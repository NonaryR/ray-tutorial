{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Nested Parallelism\n",
    "\n",
    "**GOAL:** The goal of this exercise is to show how to create nested tasks by calling a remote function inside of another remote function.\n",
    "\n",
    "In this exercise, you will implement the structure of a parallel hyperparameter sweep which trains a number of models in parallel. Each model will be trained using parallel gradient computations.\n",
    "\n",
    "### Concepts for this Exercise - Nested Remote Functions\n",
    "\n",
    "Remote functions can call other functions. For example, consider the following.\n",
    "\n",
    "```python\n",
    "@ray.remote\n",
    "def f():\n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def g():\n",
    "    # Call f 4 times and return the resulting object IDs.\n",
    "    return [f.remote() for _ in range(4)]\n",
    "\n",
    "@ray.remote\n",
    "def h():\n",
    "    # Call f 4 times, block until those 4 tasks finish,\n",
    "    # retrieve the results, and return the values.\n",
    "    return ray.get([f.remote() for _ in range(4)])\n",
    "```\n",
    "\n",
    "Then calling `g` and `h` produces the following behavior.\n",
    "\n",
    "```python\n",
    ">>> ray.get(g.remote())\n",
    "[ObjectID(b1457ba0911ae84989aae86f89409e953dd9a80e),\n",
    " ObjectID(7c14a1d13a56d8dc01e800761a66f09201104275),\n",
    " ObjectID(99763728ffc1a2c0766a2000ebabded52514e9a6),\n",
    " ObjectID(9c2f372e1933b04b2936bb6f58161285829b9914)]\n",
    "\n",
    ">>> ray.get(h.remote())\n",
    "[1, 1, 1, 1]\n",
    "```\n",
    "\n",
    "**One limitation** is that the definition of `f` must come before the definitions of `g` and `h` because as soon as `g` is defined, it will be pickled and shipped to the workers, and so if `f` hasn't been defined yet, the definition will be incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import ray\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for redis server at 127.0.0.1:19479 to respond...\n",
      "Waiting for redis server at 127.0.0.1:18958 to respond...\n",
      "Starting local scheduler with 9 CPUs, 0 GPUs\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui42278.ipynb?token=3ea9506cf13535c7dd7420da299adb9f44642fc1d4ad87df\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler2216096'],\n",
       " 'node_ip_address': '127.0.0.1',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store8375638', manager_name='/tmp/plasma_manager65974989', manager_port=62709)],\n",
       " 'redis_address': '127.0.0.1:19479',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui42278.ipynb?token=3ea9506cf13535c7dd7420da299adb9f44642fc1d4ad87df'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(num_cpus=9, redirect_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example represents a hyperparameter sweep in which multiple models are trained in parallel. Each model training task also performs data parallel gradient computations.\n",
    "\n",
    "**EXERCISE:** Turn `compute_gradient` and `train_model` into remote functions so that they can be executed in parallel. Inside of `train_model`, do the calls to `compute_gradient` in parallel and fetch the results using `ray.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def compute_gradient(data):\n",
    "    time.sleep(0.03)\n",
    "    return 1\n",
    "\n",
    "@ray.remote\n",
    "def train_model(hyperparameters):\n",
    "    result = 0\n",
    "    for i in range(10):\n",
    "        # EXERCISE: After you turn \"compute_gradient\" into a remote function,\n",
    "        # you will need to call it with \".remote\". The results must be retrieved\n",
    "        # with \"ray.get\" before \"sum\" is called.\n",
    "        result += sum(ray.get([compute_gradient.remote(j) for j in range(2)]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** The code below runs 3 hyperparameter experiments. Change this to run the experiments in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 ms, sys: 1.21 ms, total: 3.07 ms\n",
      "Wall time: 2.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sleep a little to improve the accuracy of the timing measurements below.\n",
    "time.sleep(2.0)\n",
    "start_time = time.time()\n",
    "\n",
    "# Run some hyperparaameter experiments.\n",
    "results = []\n",
    "for hyperparameters in [{'learning_rate': 1e-1, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-2, 'batch_size': 100},\n",
    "                        {'learning_rate': 1e-3, 'batch_size': 100}]:\n",
    "    results.append(train_model.remote(hyperparameters))\n",
    "\n",
    "results = [ray.get(i) for i in results]\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([20, 20, 20], 0.34412097930908203)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VERIFY:** Run some checks to verify that the changes you made to the code were correct. Some of the checks should fail when you initially run the cells. After completing the exercises, the checks should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The example took 0.34412097930908203 seconds.\n"
     ]
    }
   ],
   "source": [
    "assert results == [20, 20, 20]\n",
    "assert duration < 0.5, ('The experiments ran in {} seconds. This is too '\n",
    "                         'slow.'.format(duration))\n",
    "assert duration > 0.3, ('The experiments ran in {} seconds. This is too '\n",
    "                        'fast.'.format(duration))\n",
    "\n",
    "print('Success! The example took {} seconds.'.format(duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE:** Use the UI to view the task timeline and to verify that the pattern makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358658a8a90f4a5ea4db957d52140672"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb06e1bd3d74317af393f06ca1d3826"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c22c856ae4f48918c53c083093226cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c79c8ebcbb48e5995a9b0ca2869c11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b455b3fc9f5242edbf7c8666863a4095"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ray.experimental.ui as ui\n",
    "ui.task_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
